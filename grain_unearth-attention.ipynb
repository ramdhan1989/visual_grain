{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2716,
     "status": "ok",
     "timestamp": 1624439925606,
     "user": {
      "displayName": "ramdhan wibawa",
      "photoUrl": "",
      "userId": "14519448541243845830"
     },
     "user_tz": -420
    },
    "id": "mW8mQghJfh6D"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "from os import getenv\n",
    "from os.path import abspath, basename, split,dirname\n",
    "import tarfile\n",
    "from shutil import copyfile\n",
    "import random, glob\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "from skimage.util import random_noise\n",
    "from skimage.transform import rotate\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.applications import EfficientNetB0,EfficientNetB3, EfficientNetB2\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet import ResNet101\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201\n",
    "from tensorflow.keras.applications.nasnet import NASNetLarge, NASNetMobile\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "#from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "ds_build_cmd = \"tfds build grains --manual_dir=\" + \"D:/Ramdhan/Unearth/visual-grain-analysis/data/public2\"\n",
    "logger.info(ds_build_cmd)\n",
    "os.system(ds_build_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 493,
     "status": "ok",
     "timestamp": 1624440223471,
     "user": {
      "displayName": "ramdhan wibawa",
      "photoUrl": "",
      "userId": "14519448541243845830"
     },
     "user_tz": -420
    },
    "id": "-GFNqiGNfh6F"
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "IMG_SIZE = 224\n",
    "LBL = dict(zip(['B_BSMUT1', 'B_CLEV5B', 'B_DISTO', 'B_GRMEND', 'B_HDBARL',\n",
    "       'B_PICKLD', 'B_SKINED', 'B_SOUND', 'B_SPRTED', 'B_SPTMLD',\n",
    "       'O_GROAT', 'O_HDOATS', 'O_SEPAFF', 'O_SOUND', 'O_SPOTMA',\n",
    "       'WD_RADPODS', 'WD_RYEGRASS', 'WD_SPEARGRASS', 'WD_WILDOATS',\n",
    "       'W_DISTO', 'W_FLDFUN', 'W_INSDA2', 'W_PICKLE', 'W_SEVERE',\n",
    "       'W_SOUND', 'W_SPROUT', 'W_STAIND', 'W_WHITEG'], range(28)))\n",
    "\n",
    "cls_map = dict(zip(LBL.values(),LBL.keys()))\n",
    "\n",
    "model_version = '001'\n",
    "\n",
    "# Work around for a SageMaker path issue\n",
    "# (see https://github.com/aws/sagemaker-python-sdk/issues/648)\n",
    "# WARNING - removing this may cause the submission process to fail\n",
    "#if abspath(\"D:/Ramdhan/Unearth/visual-grain-analysis\") not in sys.path:\n",
    " #   sys.path.append(abspath(\"D:/Ramdhan/Unearth/visual-grain-analysis\"))\n",
    "\n",
    "def input_preprocess(image, label):\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    return image, label\n",
    "\n",
    "def get_subfolders(directory):\n",
    "    subfolders = os.listdir(directory)\n",
    "    subfolders.sort()\n",
    "    return subfolders\n",
    "\n",
    "def save_class_list(class_list):\n",
    "    class_list.sort()\n",
    "    target=open(\"class_list.txt\",'w')\n",
    "    for c in class_list:\n",
    "        target.write(c)\n",
    "        target.write(\"\\n\")\n",
    "\n",
    "def get_num_files(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        return 0\n",
    "    cnt = 0\n",
    "    for r, dirs, files in os.walk(directory):\n",
    "        for dr in dirs:\n",
    "            cnt += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
    "    return cnt\n",
    "\n",
    "def get_cosine_schedule_with_warmup(lr, num_warmup_steps, num_training_steps, num_cycles=0.5):\n",
    "    \"\"\"\n",
    "    Modified the get_cosine_schedule_with_warmup from huggingface for tensorflow\n",
    "    (https://huggingface.co/transformers/_modules/transformers/optimization.html#get_cosine_schedule_with_warmup)\n",
    "\n",
    "    Create a schedule with a learning rate that decreases following the\n",
    "    values of the cosine function between 0 and `pi * cycles` after a warmup\n",
    "    period during which it increases linearly between 0 and 1.\n",
    "    \"\"\"\n",
    "\n",
    "    def lrfn(epoch):\n",
    "        if epoch < num_warmup_steps:\n",
    "            return float(epoch) / float(max(1, num_warmup_steps)) * lr\n",
    "        progress = float(epoch - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr\n",
    "\n",
    "    return tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n",
    "\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    #img = tf.image.resize(img, (224, 224))\n",
    "    img = tf.image.random_crop(img, size=[random_crop_size, random_crop_size, 3])\n",
    "    img = tf.image.resize(img, (224, 224))\n",
    "    return img\n",
    "\n",
    "def noise(img):\n",
    "    img = random_noise(img, mode='speckle', mean=0, var=0.05, clip=True)\n",
    "    return img\n",
    "\n",
    "def saturation(img):\n",
    "    img = tf.image.random_hue(img, max_delta=0.2)\n",
    "    return img\n",
    "\n",
    "def resize_pad(img):\n",
    "    #img = tf.image.resize_with_pad(img, 224, 224,method='nearest')\n",
    "    img = tf.image.resize(img, (224, 224),method='nearest')\n",
    "    return img\n",
    "\n",
    "def random_rotation(image_array):\n",
    "    # pick a random degree of rotation between 25% on the left and 25% on the right\n",
    "    random_degree = random.uniform(-180, 180)\n",
    "    return rotate(image_array, random_degree, mode='edge')\n",
    "\n",
    "def rotation_generator(batches):\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], 224, 224, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = resize_pad(batch_x[i])\n",
    "            batch_crops[i] = random_rotation(batch_x[i])\n",
    "        yield (batch_crops, batch_y)\n",
    "\n",
    "def saturation_generator(batches):\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], 224, 224, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = saturation(batch_x[i])\n",
    "        yield (batch_crops, batch_y)\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n",
    "    crops from the image batches generated by the original iterator.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], 224, 224, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], crop_length)\n",
    "        yield (batch_crops, batch_y)\n",
    "        \n",
    "def noise_generator(batches):\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], 224, 224, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = noise(batch_x[i])\n",
    "        yield (batch_crops, batch_y)\n",
    "\n",
    "def train(args):\n",
    "    global NUM_CLASSES\n",
    "    \"\"\"Train\n",
    "    \"\"\"\n",
    "    logger.info(\"calling training function\")\n",
    "\n",
    "    ### Build the tensorflow dataset from downloaded files\n",
    "    \n",
    "    train_datagen =  ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                       #rotation_range=180,\n",
    "                                      #shear_range=args.shear,\n",
    "                                      #zoom_range=2,\n",
    "                                      #horizontal_flip=True,\n",
    "                                      #vertical_flip=True,\n",
    "                                      #fill_mode=\"nearest\",\n",
    "                                      #width_shift_range=args.shear,\n",
    "                                      #height_shift_range=args.shear,\n",
    "                                      #brightness_range = [0,0.1],\n",
    "                                      #channel_shift_range = 0.5,\n",
    "                                      #rescale=1.0 / 255,\n",
    "                                       )\n",
    "      \n",
    "\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    \n",
    "    TRAIN_DIR = os.path.join(args['data_dir'],  'train')\n",
    "    VAL_DIR = os.path.join(args['data_dir'], 'val')\n",
    "    \n",
    "    size = (IMG_SIZE, IMG_SIZE)\n",
    "    batch_size = 32\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(TRAIN_DIR, target_size=size, batch_size=batch_size)\n",
    "    samples = train_generator.samples\n",
    "    train_crops = rotation_generator(train_generator)\n",
    "\n",
    "    validation_generator = val_datagen.flow_from_directory(VAL_DIR, target_size=size, batch_size=batch_size)\n",
    "    \n",
    "    #ds_build_cmd = \"tfds build grains --manual_dir=\" + args['data_dir']\n",
    "    #logger.info(ds_build_cmd)\n",
    "    #os.system(ds_build_cmd)\n",
    "\n",
    "    logger.info(\"Training Model\")\n",
    "    #strategy = tf.distribute.MirroredStrategy()\n",
    "    \n",
    "    #dataset_name = \"grains\"\n",
    "    #(ds_train, ds_test), ds_info = tfds.load(dataset_name, split=[\"train\", \"val\"], with_info=True, as_supervised=True)\n",
    "    class_list = get_subfolders(TRAIN_DIR)\n",
    "    NUM_CLASSES = len(class_list)\n",
    "    save_class_list(class_list)\n",
    "\n",
    "    num_train_images = get_num_files(TRAIN_DIR)\n",
    "    num_val_images = get_num_files(VAL_DIR)\n",
    "\n",
    "    logger.info(\"number of classes is \" + str(NUM_CLASSES))\n",
    "\n",
    "    #with strategy.scope():\n",
    "    #model = build_model(num_classes=NUM_CLASSES)\n",
    "    model = build_model_attention2(num_classes=NUM_CLASSES)\n",
    "    #model = build_model2(dropout=0.5, fc_layers=[512], num_classes=NUM_CLASSES)\n",
    "    filename = 'best.h5'\n",
    "    #reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "    checkpoint = ModelCheckpoint(filename, monitor='val_acc_grain', verbose=1, save_best_only=True, mode='max')\n",
    "    stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=40, mode= 'min', min_delta=0.00)\n",
    "    lr_schedule= get_cosine_schedule_with_warmup(lr=0.001, num_warmup_steps=4, num_training_steps=25)\n",
    "\n",
    "    # This comes from an environment variable so we can set it to 1 for our\n",
    "    # development pipeline. Feel free to set this to any value.\n",
    "    weights = dict(zip([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27], [1,1,1,1,1,1,1,8.94,1,1,1,1,1,8.94,1,1,1,1,1,1,1,1,1,1,8.94,1,1,1]))\n",
    "\n",
    "    history = model.fit(train_crops, epochs=25, validation_data=validation_generator, shuffle=True,\n",
    "                        callbacks=[stop, checkpoint,lr_schedule],steps_per_epoch=samples/batch_size,\n",
    "              verbose=1, class_weight=weights\n",
    "                        #, workers=0, steps_per_epoch=num_train_images // batch_size, \n",
    "        #, validation_steps=num_val_images // batch_size,shuffle=True\n",
    "                       )\n",
    "    #save_model(model,args['model_dir'])\n",
    "    #save_model(model,filename)\n",
    "    \n",
    "    return history\n",
    "\n",
    "def acc_grain(y_true, y_pred):\n",
    "    y_true_class = K.argmax(y_true, axis=-1)\n",
    "    y_pred_class = K.argmax(y_pred, axis=-1)\n",
    "    sample_weight = np.hstack((np.where(y_true_class.numpy().reshape(-1,1)==7,True,False),np.where(y_true_class.numpy().reshape(-1,1)==24,True,False),np.where(y_true_class.numpy().reshape(-1,1)==13,True,False)))\n",
    "    sample_weight = np.any(sample_weight,axis=1)\n",
    "    sample_weight = np.where(sample_weight,8.94,1.0)\n",
    "    return K.constant(accuracy_score(y_true_class,y_pred_class,sample_weight=sample_weight))\n",
    "\n",
    "def build_model_attention(num_classes):\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    model = EfficientNetB2(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
    "    for layer in model.layers[:-1]:\n",
    "        layer.trainable = False\n",
    "    #model.trainable = False\n",
    "    pt_features = model(inputs)\n",
    "    pt_depth = model.get_output_shape_at(0)[-1]\n",
    "    bn_features = layers.BatchNormalization()(pt_features)\n",
    "    \n",
    "     # here we do an attention mechanism to turn pixels in the GAP on an off\n",
    "    attn_layer = layers.Conv2D(64, kernel_size = (1, 1), padding = 'same', activation = 'swish')(layers.Dropout(0.5)(bn_features))\n",
    "    attn_layer = layers.Conv2D(16, kernel_size = (1, 1), padding = 'same', activation = 'swish')(attn_layer)\n",
    "    attn_layer = layers.Conv2D(8, kernel_size = (1,1), padding = 'same', activation = 'swish')(attn_layer)\n",
    "    attn_layer = layers.Conv2D(1, kernel_size = (1, 1), padding = 'valid', activation = 'sigmoid')(attn_layer)\n",
    "    \n",
    "    # fan it out to all of the channels\n",
    "    up_c2_w = np.ones((1, 1, 1, pt_depth))\n",
    "    up_c2 = layers.Conv2D(pt_depth,kernel_size=(1,1),padding = 'same', activation='linear',use_bias = False,weights = [up_c2_w] )\n",
    "    up_c2.trainable = False\n",
    "    attn_layer = up_c2(attn_layer)\n",
    "    mask_features = layers.multiply([attn_layer, bn_features])\n",
    "    gap_features = layers.GlobalAveragePooling2D()(mask_features)\n",
    "    gap_mask = layers.GlobalAveragePooling2D()(attn_layer)\n",
    "    \n",
    "     # To account for missing values from the attention model\n",
    "    gap = layers.Lambda(lambda x: x[0] / x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n",
    "    gap_dr = layers.Dropout(0.5)(gap)\n",
    "    dr_steps = layers.Dropout(0.25)(tf.keras.layers.Dense(128, activation = 'swish')(gap_dr))\n",
    "    \n",
    "    concat = layers.BatchNormalization()(dr_steps)\n",
    "    concat = layers.Dense(512, activation = 'swish')(concat)        \n",
    "    concat = layers.Dropout(0.15)(concat)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"pred\",dtype='float32')(concat)\n",
    "\n",
    "    model = tf.keras.Model([inputs], [outputs], name=\"EfficientNet\")\n",
    "    #optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[acc_grain],run_eagerly=True)\n",
    "    return model\n",
    "\n",
    "def build_model_attention2(num_classes):\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    model = EfficientNetB2(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
    "    #for layer in model.layers[:-1]:\n",
    "        #layer.trainable = False\n",
    "    model.trainable = False\n",
    "    pt_features = model(inputs)\n",
    "    pt_depth = model.get_output_shape_at(0)[-1]\n",
    "    bn_features = layers.BatchNormalization()(pt_features)\n",
    "    \n",
    "     # here we do an attention mechanism to turn pixels in the GAP on an off   \n",
    "    attn_layer = layers.Conv2D(64, kernel_size = (1,1), padding = 'same', activation = 'relu')(bn_features)\n",
    "    attn_layer = layers.Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n",
    "    attn_layer = layers.LocallyConnected2D(1, kernel_size = (1,1), padding = 'valid', activation = 'sigmoid')(attn_layer)\n",
    "    \n",
    "    up_c2_w = np.ones((1, 1, 1, pt_depth))\n",
    "    up_c2 =  layers.Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', activation = 'linear', use_bias = False, weights = [up_c2_w])\n",
    "    up_c2.trainable = False\n",
    "    attn_layer = up_c2(attn_layer)\n",
    "\n",
    "    mask_features =  layers.multiply([attn_layer, bn_features])\n",
    "    gap_features =  layers.GlobalAveragePooling2D()(mask_features)\n",
    "    gap_mask =  layers.GlobalAveragePooling2D()(attn_layer)\n",
    "    # to account for missing values from the attention model\n",
    "    gap =  layers.Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n",
    "    gap_dr =  layers.Dropout(0.5)(gap)\n",
    "    dr_steps =  layers.Dropout(0.25)( layers.Dense(1024, activation = 'elu')(gap_dr))\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"pred\",dtype='float32')(dr_steps)\n",
    "\n",
    "    model = tf.keras.Model([inputs], [outputs], name=\"EfficientNet\")\n",
    "    #optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[acc_grain],run_eagerly=True)\n",
    "    return model\n",
    "\n",
    "def save_model(model, model_dir):\n",
    "    \"\"\"Save model to a binary file.\n",
    "\n",
    "    This function must write the model to disk in a format that can\n",
    "    be loaded from the model_fn.\n",
    "\n",
    "    WARNING - modifying this function may cause the submission process to fail.\n",
    "    \"\"\"\n",
    "    #sm_model_dir = os.path.join(model_dir, model_version)\n",
    "    sm_model_dir = model_dir\n",
    "    if (not os.path.isdir(sm_model_dir)):\n",
    "        os.makedirs(sm_model_dir)\n",
    "        \n",
    "    logger.info(f\" model dir is {model_dir}\")\n",
    "    model.save(sm_model_dir)\n",
    "    \n",
    "    modelPath = os.path.join(sm_model_dir, 'output')\n",
    "    if (not os.path.isdir(modelPath)):\n",
    "        os.makedirs(modelPath)\n",
    "    #if (not os.path.isdir(sm_model_dir + '/code')):\n",
    "        #os.makedirs(sm_model_dir + '/code')\n",
    "\n",
    "    # Move inference.py so it gets picked up in the archive\n",
    "    #copyfile('/content/sample_data/inference.py', sm_model_dir + '/code/inference.py')\n",
    "    #copyfile('/content/sample_data/inference-requirements.txt', sm_model_dir+ '/code/requirements.txt')\n",
    "\n",
    "    with tarfile.open(os.path.join(modelPath, 'model.tar.gz'), mode='x:gz') as archive:\n",
    "        archive.add(sm_model_dir, recursive=True)\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Load model from binary file.\n",
    "\n",
    "    This function loads the model from disk. It is called by SageMaker.\n",
    "\n",
    "    WARNING - modifying this function may case the submission process to fail.\n",
    "    \"\"\"\n",
    "    #model_filepath = os.path.join(model_dir,  model_version)\n",
    "    #logger.info(\"loading model from \" + model_filepath)\n",
    "    model = keras.models.load_model('best.h5',custom_objects={'acc_grain':acc_grain},compile=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "executionInfo": {
     "elapsed": 38441,
     "status": "error",
     "timestamp": 1624440265326,
     "user": {
      "displayName": "ramdhan wibawa",
      "photoUrl": "",
      "userId": "14519448541243845830"
     },
     "user_tz": -420
    },
    "id": "RLmWtwmRfh6P",
    "outputId": "e5e2ae19-620c-4d31-f907-12bb2132639e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:calling training function\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19182 images belonging to 28 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Training Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7648 images belonging to 28 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:number of classes is 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0.\n",
      "Epoch 1/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 23.5603 - acc_grain: 0.0244\n",
      "Epoch 00001: val_acc_grain improved from -inf to 0.01265, saving model to best.h5\n",
      "600/599 [==============================] - 385s 642ms/step - loss: 23.5603 - acc_grain: 0.0244 - val_loss: 3.5856 - val_acc_grain: 0.0126\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.00025.\n",
      "Epoch 2/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 2.8444 - acc_grain: 0.9001\n",
      "Epoch 00002: val_acc_grain improved from 0.01265 to 0.94895, saving model to best.h5\n",
      "600/599 [==============================] - 383s 639ms/step - loss: 2.8444 - acc_grain: 0.9001 - val_loss: 1.2337 - val_acc_grain: 0.9490\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 3/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 1.8593 - acc_grain: 0.9280\n",
      "Epoch 00003: val_acc_grain improved from 0.94895 to 0.95163, saving model to best.h5\n",
      "600/599 [==============================] - 382s 637ms/step - loss: 1.8593 - acc_grain: 0.9280 - val_loss: 1.0235 - val_acc_grain: 0.9516\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.00075.\n",
      "Epoch 4/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 1.7928 - acc_grain: 0.9278\n",
      "Epoch 00004: val_acc_grain improved from 0.95163 to 0.95342, saving model to best.h5\n",
      "600/599 [==============================] - 387s 646ms/step - loss: 1.7928 - acc_grain: 0.9278 - val_loss: 1.1111 - val_acc_grain: 0.9534\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 5/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 1.7167 - acc_grain: 0.9314\n",
      "Epoch 00005: val_acc_grain improved from 0.95342 to 0.95439, saving model to best.h5\n",
      "600/599 [==============================] - 390s 649ms/step - loss: 1.7167 - acc_grain: 0.9314 - val_loss: 1.1489 - val_acc_grain: 0.9544\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0009944154131125641.\n",
      "Epoch 6/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 1.6752 - acc_grain: 0.9340\n",
      "Epoch 00006: val_acc_grain improved from 0.95439 to 0.95617, saving model to best.h5\n",
      "600/599 [==============================] - 387s 646ms/step - loss: 1.6752 - acc_grain: 0.9340 - val_loss: 0.9179 - val_acc_grain: 0.9562\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0009777864028930705.\n",
      "Epoch 7/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 1.5810 - acc_grain: 0.9367\n",
      "Epoch 00007: val_acc_grain did not improve from 0.95617\n",
      "600/599 [==============================] - 384s 640ms/step - loss: 1.5810 - acc_grain: 0.9367 - val_loss: 0.9558 - val_acc_grain: 0.9561\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0009504844339512095.\n",
      "Epoch 8/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 1.5542 - acc_grain: 0.9394\n",
      "Epoch 00008: val_acc_grain improved from 0.95617 to 0.95672, saving model to best.h5\n",
      "600/599 [==============================] - 382s 637ms/step - loss: 1.5542 - acc_grain: 0.9394 - val_loss: 0.9023 - val_acc_grain: 0.9567\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0009131193871579975.\n",
      "Epoch 9/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 1.4737 - acc_grain: 0.9438\n",
      "Epoch 00009: val_acc_grain improved from 0.95672 to 0.96384, saving model to best.h5\n",
      "600/599 [==============================] - 384s 639ms/step - loss: 1.4737 - acc_grain: 0.9438 - val_loss: 0.7602 - val_acc_grain: 0.9638\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0008665259359149131.\n",
      "Epoch 10/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 1.4870 - acc_grain: 0.9409\n",
      "Epoch 00010: val_acc_grain did not improve from 0.96384\n",
      "600/599 [==============================] - 396s 660ms/step - loss: 1.4870 - acc_grain: 0.9409 - val_loss: 0.8617 - val_acc_grain: 0.9616\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0008117449009293668.\n",
      "Epoch 11/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 1.3837 - acc_grain: 0.9468\n",
      "Epoch 00011: val_acc_grain did not improve from 0.96384\n",
      "600/599 [==============================] - 394s 657ms/step - loss: 1.3837 - acc_grain: 0.9468 - val_loss: 0.9308 - val_acc_grain: 0.9596\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.00075.\n",
      "Epoch 12/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 1.3420 - acc_grain: 0.9488\n",
      "Epoch 00012: val_acc_grain did not improve from 0.96384\n",
      "600/599 [==============================] - 396s 660ms/step - loss: 1.3420 - acc_grain: 0.9488 - val_loss: 0.8670 - val_acc_grain: 0.9611\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0006826705121831977.\n",
      "Epoch 13/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 1.3558 - acc_grain: 0.9488\n",
      "Epoch 00013: val_acc_grain did not improve from 0.96384\n",
      "600/599 [==============================] - 393s 655ms/step - loss: 1.3558 - acc_grain: 0.9488 - val_loss: 0.8486 - val_acc_grain: 0.9608\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0006112604669781572.\n",
      "Epoch 14/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 1.2438 - acc_grain: 0.9503\n",
      "Epoch 00014: val_acc_grain did not improve from 0.96384\n",
      "600/599 [==============================] - 395s 658ms/step - loss: 1.2438 - acc_grain: 0.9503 - val_loss: 0.7584 - val_acc_grain: 0.9636\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0005373650467932121.\n",
      "Epoch 15/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 1.2003 - acc_grain: 0.9527\n",
      "Epoch 00015: val_acc_grain improved from 0.96384 to 0.96561, saving model to best.h5\n",
      "600/599 [==============================] - 396s 659ms/step - loss: 1.2003 - acc_grain: 0.9527 - val_loss: 0.7651 - val_acc_grain: 0.9656\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0004626349532067879.\n",
      "Epoch 16/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 1.1699 - acc_grain: 0.9546\n",
      "Epoch 00016: val_acc_grain did not improve from 0.96561\n",
      "600/599 [==============================] - 393s 655ms/step - loss: 1.1699 - acc_grain: 0.9546 - val_loss: 0.8480 - val_acc_grain: 0.9630\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.00038873953302184284.\n",
      "Epoch 17/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 1.1334 - acc_grain: 0.9553\n",
      "Epoch 00017: val_acc_grain did not improve from 0.96561\n",
      "600/599 [==============================] - 394s 657ms/step - loss: 1.1334 - acc_grain: 0.9553 - val_loss: 0.7255 - val_acc_grain: 0.9652\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0003173294878168025.\n",
      "Epoch 18/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 1.0816 - acc_grain: 0.9581\n",
      "Epoch 00018: val_acc_grain improved from 0.96561 to 0.96581, saving model to best.h5\n",
      "600/599 [==============================] - 390s 651ms/step - loss: 1.0816 - acc_grain: 0.9581 - val_loss: 0.7225 - val_acc_grain: 0.9658\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0002500000000000001.\n",
      "Epoch 19/25\n",
      "600/599 [==============================] - ETA: 0s - loss: 1.0499 - acc_grain: 0.9583\n",
      "Epoch 00019: val_acc_grain improved from 0.96581 to 0.96626, saving model to best.h5\n",
      "600/599 [==============================] - 388s 646ms/step - loss: 1.0499 - acc_grain: 0.9583 - val_loss: 0.6993 - val_acc_grain: 0.9663\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.00018825509907063325.\n",
      "Epoch 20/25\n",
      "568/599 [===========================>..] - ETA: 1:43 - loss: 1.0271 - acc_grain: 0.9580"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "INFO:root:\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\Anaconda3\\envs\\object_detection_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-f940733bccd2>\", line 15, in <module>\n",
      "    history = train(args)\n",
      "  File \"<ipython-input-2-79d3459c9e51>\", line 197, in train\n",
      "    verbose=1, class_weight=weights\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 108, in _method_wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1098, in fit\n",
      "    tmp_logs = train_function(iterator)\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 806, in train_function\n",
      "    return step_function(self, iterator)\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 796, in step_function\n",
      "    outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 1211, in run\n",
      "    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 2585, in call_for_each_replica\n",
      "    return self._call_for_each_replica(fn, args, kwargs)\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 2945, in _call_for_each_replica\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 789, in run_step\n",
      "    outputs = model.train_step(data)\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 757, in train_step\n",
      "    self.trainable_variables)\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 2722, in _minimize\n",
      "    gradients = tape.gradient(loss, trainable_variables)\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\backprop.py\", line 1073, in gradient\n",
      "    unconnected_gradients=unconnected_gradients)\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\", line 77, in imperative_grad\n",
      "    compat.as_str(unconnected_gradients.value))\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\backprop.py\", line 162, in _gradient_function\n",
      "    return grad_fn(mock_op, *out_grads)\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_grad.py\", line 266, in _MeanGrad\n",
      "    return math_ops.truediv(sum_grad, math_ops.cast(factor, sum_grad.dtype)), None\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1297, in truediv\n",
      "    return _truediv_python3(x, y, name)\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1236, in _truediv_python3\n",
      "    return gen_math_ops.real_div(x, y, name=name)\n",
      "  File \"C:\\Users\\Owner\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 7440, in real_div\n",
      "    tld.op_callbacks, x, y)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\Anaconda3\\envs\\object_detection_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\Anaconda3\\envs\\object_detection_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Owner\\Anaconda3\\envs\\object_detection_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Owner\\Anaconda3\\envs\\object_detection_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Owner\\Anaconda3\\envs\\object_detection_gpu\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Owner\\Anaconda3\\envs\\object_detection_gpu\\lib\\inspect.py\", line 1452, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"C:\\Users\\Owner\\Anaconda3\\envs\\object_detection_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 185, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"C:\\Users\\Owner\\Anaconda3\\envs\\object_detection_gpu\\lib\\linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"C:\\Users\\Owner\\Anaconda3\\envs\\object_detection_gpu\\lib\\linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"C:\\Users\\Owner\\Anaconda3\\envs\\object_detection_gpu\\lib\\tokenize.py\", line 452, in open\n",
      "    buffer = _builtin_open(filename, 'rb')\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"Training Main\n",
    "\n",
    "    The main function is called by both Unearthed's SageMaker pipeline and the\n",
    "    Unearthed CLI's \"unearthed train\" command.\n",
    "    \n",
    "    WARNING - modifying this function may cause the submission process to fail.\n",
    "\n",
    "    The main function must call preprocess, arrange th\n",
    "    \"\"\"\n",
    "    \n",
    "    args = {'model_dir': \"D:/Ramdhan/Unearth/visual-grain-analysis/models/\",\n",
    "           'data_dir' : \"D:/Ramdhan/Unearth/visual-grain-analysis/data/public/\"}\n",
    "    start = time.time()\n",
    "    history = train(args)\n",
    "    print('duration run',(time.time()-start)/60/60,' hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c0f16a08d160>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m121\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc_grain'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc_grain'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model acc_score'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training & validation iou_score values\n",
    "plt.figure(figsize=(30, 20))\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['acc_grain'])\n",
    "plt.plot(history.history['val_acc_grain'])\n",
    "plt.title('Model acc_score')\n",
    "plt.ylabel('acc_score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 2298,
     "status": "error",
     "timestamp": 1624373965288,
     "user": {
      "displayName": "ramdhan wibawa",
      "photoUrl": "",
      "userId": "14519448541243845830"
     },
     "user_tz": -420
    },
    "id": "UejZgfeXZ5C7",
    "outputId": "fbfcc699-a9ac-4b16-ccbb-0a8c4a25222e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:loading the model\n",
      "INFO:__main__:Reading the test set\n",
      "INFO:__main__:predictions have shape of (7648, 9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.9714785826952912\n",
      "Duration Run 0.1071839827961392  hours\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import csv\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "def load_class_list(class_list_file):\n",
    "    class_list = []\n",
    "    with open(class_list_file, 'r') as csvfile:\n",
    "        file_reader = csv.reader(csvfile)\n",
    "        for row in file_reader:\n",
    "            class_list.append(row[0])\n",
    "    class_list.sort()\n",
    "    return class_list\n",
    "\n",
    "class_list = load_class_list('class_list.txt')\n",
    "\n",
    "IMG_SIZE=224\n",
    "LBL = dict(zip(class_list, range(28)))\n",
    "\n",
    "cls_map = dict(zip(LBL.values(),LBL.keys()))\n",
    "\n",
    "def init_dir(pth):\n",
    "    if os.path.exists(pth):\n",
    "        shutil.rmtree(pth)\n",
    "    os.mkdir(pth)\n",
    "\n",
    "logger.info(\"loading the model\")\n",
    "model = model_fn(args['model_dir'])\n",
    "logger.info(\"Reading the test set\")\n",
    "\n",
    "res = []\n",
    "for fn in glob.iglob(args['data_dir'] + 'val/**/*.png', recursive=True):\n",
    "    file_name = os.path.basename(fn)\n",
    "    path = os.path.abspath(fn)\n",
    "    folder = os.path.split(os.path.dirname(path))[1]\n",
    "    if len(file_name.split(\"-\")) > 2:  # ignore master image with may grains, raw image names are in guid format\n",
    "        im = image.load_img(path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "        img_array = image.img_to_array(im)\n",
    "        img_batch = np.expand_dims(img_array, axis=0)\n",
    "        img_preprocessed = preprocess_input(img_batch)\n",
    "        pred = model.predict(img_preprocessed)\n",
    "        top3 = (-pred[0]).argsort()[:3]\n",
    "        res.append({'file_name': file_name, 'path': path, 'cls': folder, 'prediction':top3[0],  'proba_1':pred[0][top3[0]], 'prediction2':top3[1], 'proba_2':pred[0][top3[1]],  'prediction3':top3[2], 'proba_3':pred[0][top3[2]]})\n",
    "\n",
    "df = pd.DataFrame(res)\n",
    "df['prediction'] = df.prediction.map(cls_map)\n",
    "df['prediction2'] = df.prediction2.map(cls_map)\n",
    "df['prediction3'] = df.prediction3.map(cls_map)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def w(x):\n",
    "    if \"_SOUND\" in x:\n",
    "        return 8.94 # weighting  Healthy grains more important than defective grains\n",
    "    return 1\n",
    "\n",
    "def scoring_fn(df):\n",
    "    \"\"\"\n",
    "    Weighted Accuracy Metric 90% Healthy grains, 10% unhealthy grains\n",
    "    \"\"\"\n",
    "    df['weight'] = df.cls.apply(w)\n",
    "    return accuracy_score(df.cls,df.prediction,sample_weight=df.weight)\n",
    "\n",
    "logger.info(f\"predictions have shape of {df.shape}\")\n",
    "\n",
    "score = scoring_fn(df)\n",
    "print (\"Accuracy Score:\" + str(score))\n",
    "# write to the output location\n",
    "\n",
    "print('Duration Run',(time.time()-start)/3600,' hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     B_BSMUT1       0.99      0.83      0.90       105\n",
      "     B_CLEV5B       0.95      0.37      0.53       100\n",
      "      B_DISTO       0.86      0.37      0.52       100\n",
      "     B_GRMEND       0.95      0.47      0.63        88\n",
      "     B_HDBARL       1.00      0.03      0.06        30\n",
      "     B_PICKLD       1.00      0.28      0.44        92\n",
      "     B_SKINED       0.97      0.35      0.52        88\n",
      "      B_SOUND       0.79      1.00      0.88      1653\n",
      "     B_SPRTED       0.98      0.89      0.93        93\n",
      "     B_SPTMLD       0.93      0.22      0.36       112\n",
      "      O_GROAT       0.98      0.62      0.76        90\n",
      "     O_HDOATS       0.91      0.10      0.18        99\n",
      "     O_SEPAFF       0.84      0.61      0.71       109\n",
      "      O_SOUND       0.90      1.00      0.95      1988\n",
      "     O_SPOTMA       0.89      0.23      0.37       103\n",
      "   WD_RADPODS       1.00      0.97      0.98        94\n",
      "  WD_RYEGRASS       0.99      0.93      0.96        87\n",
      "WD_SPEARGRASS       0.99      0.95      0.97        94\n",
      "  WD_WILDOATS       0.99      0.95      0.97        92\n",
      "      W_DISTO       0.80      0.64      0.71       102\n",
      "     W_FLDFUN       0.75      0.09      0.15       105\n",
      "     W_INSDA2       0.83      0.52      0.64        97\n",
      "     W_PICKLE       0.93      0.53      0.67       104\n",
      "     W_SEVERE       0.97      0.86      0.91       101\n",
      "      W_SOUND       0.78      0.99      0.87      1611\n",
      "     W_SPROUT       0.96      0.24      0.39       108\n",
      "     W_STAIND       0.69      0.29      0.41        92\n",
      "     W_WHITEG       0.74      0.18      0.29       111\n",
      "\n",
      "     accuracy                           0.84      7648\n",
      "    macro avg       0.91      0.55      0.63      7648\n",
      " weighted avg       0.85      0.84      0.81      7648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(df['cls'], df['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ticks=np.linspace(0, 27,num=28)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(confusion_matrix(df['cls'], df['prediction'],normalize='true'), interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.xticks(ticks,fontsize=6)\n",
    "plt.yticks(ticks,fontsize=6)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZXP_9Kzfh6Q"
   },
   "outputs": [],
   "source": [
    "from keras_preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0bgHcc9rskI"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES=28\n",
    "model = build_model(num_classes=NUM_CLASSES)\n",
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Fcx6Qvnfh6Q",
    "outputId": "fc7bceb9-5ffb-46bc-ffaf-7e1cf07f05c0"
   },
   "outputs": [],
   "source": [
    "image.random_rotation(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "saWJd9X3fh6R"
   },
   "outputs": [],
   "source": [
    " rotation_range=args.rotation,\n",
    "      shear_range=args.shear,\n",
    "      zoom_range=args.zoom,\n",
    "      horizontal_flip=args.h_flip,\n",
    "      vertical_flip=args.v_flip"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "grain_unearth.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
